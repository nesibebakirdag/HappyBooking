{"cells":[{"cell_type":"markdown","source":["# Bronze Layer: API Ingestion (Data-Driven Enrichment)\n","\n","**AmaÃ§:**\n","1. **Enrichment:** Silver'daki temizlenmiÅŸ ÅŸehirler (`city_clean`) iÃ§in gerÃ§ek hava durumu Ã§ek.\n","2. **Reference Data:** Weather ve Exchange Rate tablolarÄ± Dim Join iÃ§in kullanÄ±lÄ±r.\n","\n","**âš ï¸ Ã‡alÄ±ÅŸtÄ±rma SÄ±rasÄ±:**\n","```\n","05_silver_transformations  â†’  04_bronze_ingest_api  â†’  07_silver_dim_enrichment\n","```\n","Silver Ã¶nce Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r Ã§Ã¼nkÃ¼ temiz `city_clean` isimleri oradan okunur."],"metadata":{},"id":"7857d95a-a6b0-4110-8524-9653bd83f241"},{"cell_type":"code","source":["import requests\n","import json\n","import os\n","import datetime\n","from pyspark.sql.functions import col, to_timestamp, initcap, trim, lit, regexp_replace\n","\n","RAW_WEATHER_PATH  = \"/lakehouse/default/Files/raw_api/weather\"\n","RAW_EXCHANGE_PATH = \"/lakehouse/default/Files/raw_api/exchange\"\n","WEATHER_TABLE     = \"bronze_weather\"\n","EXCHANGE_TABLE    = \"bronze_exchange_rates\"\n","\n","def ensure_dir(path):\n","    if not os.path.exists(path):\n","        os.makedirs(path, exist_ok=True)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"98d721d9-3f04-46ab-879d-75c970076d05","normalized_state":"finished","queued_time":"2026-02-20T23:37:51.7749754Z","session_start_time":"2026-02-20T23:37:51.7758751Z","execution_start_time":"2026-02-20T23:38:05.9660652Z","execution_finish_time":"2026-02-20T23:38:06.3550386Z","parent_msg_id":"d5811aca-8a34-4465-9d06-e5a55f5de916"},"text/plain":"StatementMeta(, 98d721d9-3f04-46ab-879d-75c970076d05, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7b490c65-7dd5-43c5-b2d8-29753f96d87e"},{"cell_type":"markdown","source":["## 1. Hava Durumu (Silver city_clean â†’ Geocoding â†’ Weather API)"],"metadata":{},"id":"ea6604fe-7f1d-4c2a-aee6-73997a8a7dee"},{"cell_type":"code","source":["print(\"ğŸŒ¦ï¸ Fetching Weather Data (Data-Driven Enrichment)...\")\n","try:\n","    unique_cities = []\n","\n","    # PRIMARY SOURCE: silver_bookings.city_clean (temizlenmiÅŸ isimler, API iÃ§in ideal)\n","    try:\n","        df_silver = spark.read.table(\"silver_bookings\")\n","        city_col = \"city_clean\" if \"city_clean\" in df_silver.columns else \"city\"\n","        cities_silver = [\n","            row[city_col] for row in\n","            df_silver.select(city_col).distinct()\n","            .filter(col(city_col).isNotNull() & (col(city_col) != \"Unknown\") & (col(city_col) != \"\"))\n","            .collect()\n","        ]\n","        unique_cities.extend(cities_silver)\n","        print(f\"âœ… Silver'dan {len(cities_silver)} temiz ÅŸehir okundu.\")\n","    except Exception as e:\n","        print(f\"âš ï¸ Silver okuma hatasÄ±: {e}\")\n","\n","    # FALLBACK: Bronze'dan oku (Silver yoksa)\n","    if not unique_cities:\n","        print(\"âš ï¸ Silver bulunamadÄ±, Bronze'dan okunuyor (kirli isimler olabilir)...\")\n","        try:\n","            df_batch = spark.read.table(\"bronze_hotel_batch\")\n","            cities_batch = [row.city for row in df_batch.select(\"city\").distinct().limit(500).collect() if row.city]\n","            unique_cities.extend(cities_batch)\n","        except:\n","            pass\n","\n","    # Deduplicate\n","    unique_cities = list(set([c.strip() for c in unique_cities if c and c.strip()]))\n","\n","    if not unique_cities:\n","        unique_cities = [\"Amsterdam\", \"Berlin\", \"Paris\", \"London\", \"Istanbul\"]\n","\n","    print(f\"ğŸ“Š Toplam {len(unique_cities)} benzersiz ÅŸehir iÅŸlenecek.\")\n","    print(f\"Ã–rnek: {unique_cities[:10]}...\")\n","\n","    ensure_dir(RAW_WEATHER_PATH)\n","    weather_records = []\n","    session = requests.Session()\n","    count = 0\n","    failed = 0\n","\n","    for city in unique_cities:\n","        try:\n","            # A. Geocoding\n","            geo_url = \"https://geocoding-api.open-meteo.com/v1/search\"\n","            geo_params = {\"name\": city, \"count\": 1, \"language\": \"en\", \"format\": \"json\"}\n","            geo_resp = session.get(geo_url, params=geo_params, timeout=10)\n","            geo_data = geo_resp.json()\n","\n","            if not geo_data.get(\"results\"):\n","                failed += 1\n","                continue\n","\n","            lat     = geo_data[\"results\"][0][\"latitude\"]\n","            lon     = geo_data[\"results\"][0][\"longitude\"]\n","            country = geo_data[\"results\"][0][\"country\"]\n","\n","            # B. Weather\n","            weather_url = \"https://api.open-meteo.com/v1/forecast\"\n","            w_params = {\n","                \"latitude\": lat, \"longitude\": lon,\n","                \"current\": \"temperature_2m,relative_humidity_2m,weather_code\",\n","                \"timezone\": \"auto\"\n","            }\n","            w_resp = session.get(weather_url, params=w_params, timeout=10)\n","            w_data = w_resp.json()\n","\n","            # C. Save Raw JSON\n","            timestamp_str = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","            safe_city = city.replace(\" \", \"_\").replace(\"/\", \"_\")\n","            with open(f\"{RAW_WEATHER_PATH}/weather_{safe_city}_{timestamp_str}.json\", \"w\") as f:\n","                json.dump(w_data, f)\n","\n","            # D. Normalize\n","            current = w_data.get(\"current\", {})\n","            record = {\n","                \"city\": city,\n","                \"country_api\": country,\n","                \"latitude\": lat,\n","                \"longitude\": lon,\n","                \"temperature_c\": float(current.get(\"temperature_2m\")),\n","                \"humidity\": int(current.get(\"relative_humidity_2m\")),\n","                \"weather_code\": int(current.get(\"weather_code\")),\n","                \"recorded_at\": current.get(\"time\"),\n","                \"source\": \"open-meteo\",\n","                \"ingestion_time\": datetime.datetime.now().isoformat()\n","            }\n","            weather_records.append(record)\n","            count += 1\n","            if count % 20 == 0:\n","                print(f\"âœ… {count} ÅŸehir iÅŸlendi ({failed} baÅŸarÄ±sÄ±z)...\")\n","\n","        except Exception as inner_e:\n","            failed += 1\n","\n","    if weather_records:\n","        df_weather = spark.createDataFrame(weather_records)\n","        df_weather_normalized = df_weather \\\n","            .withColumn(\"city\", initcap(trim(col(\"city\")))) \\\n","            .withColumn(\"recorded_at\", to_timestamp(col(\"recorded_at\"))) \\\n","            .withColumn(\"ingestion_time\", to_timestamp(col(\"ingestion_time\")))\n","\n","        df_weather_normalized.write.format(\"delta\").mode(\"overwrite\") \\\n","            .option(\"overwriteSchema\", \"true\").saveAsTable(WEATHER_TABLE)\n","        print(f\"\\nâœ… {len(weather_records)} ÅŸehir kaydedildi â†’ {WEATHER_TABLE}  ({failed} ÅŸehir bulunamadÄ±)\")\n","        df_weather_normalized.select(\"city\", \"country_api\", \"temperature_c\", \"weather_code\").show(10, truncate=False)\n","    else:\n","        print(\"âš ï¸ HiÃ§bir hava durumu kaydÄ± bulunamadÄ±.\")\n","\n","except Exception as e:\n","    print(f\"âŒ Kritik Hata: {e}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"98d721d9-3f04-46ab-879d-75c970076d05","normalized_state":"finished","queued_time":"2026-02-20T23:37:51.9029653Z","session_start_time":null,"execution_start_time":"2026-02-20T23:38:06.3570667Z","execution_finish_time":"2026-02-20T23:39:10.2600544Z","parent_msg_id":"177d112f-ff58-4fc8-a072-131e34e99791"},"text/plain":"StatementMeta(, 98d721d9-3f04-46ab-879d-75c970076d05, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ğŸŒ¦ï¸ Fetching Weather Data (Data-Driven Enrichment)...\nâœ… Silver'dan 247 temiz ÅŸehir okundu.\nğŸ“Š Toplam 247 benzersiz ÅŸehir iÅŸlenecek.\nÃ–rnek: ['Trujillo', 'Chennai', 'Medina', 'Cebu', 'Johannesburg', 'Madrid', 'Paris', 'Subotica', 'Vancouver', 'Melbourne']...\nâœ… 20 ÅŸehir iÅŸlendi (1 baÅŸarÄ±sÄ±z)...\nâœ… 40 ÅŸehir iÅŸlendi (1 baÅŸarÄ±sÄ±z)...\nâœ… 60 ÅŸehir iÅŸlendi (2 baÅŸarÄ±sÄ±z)...\nâœ… 80 ÅŸehir iÅŸlendi (2 baÅŸarÄ±sÄ±z)...\nâœ… 100 ÅŸehir iÅŸlendi (2 baÅŸarÄ±sÄ±z)...\nâœ… 120 ÅŸehir iÅŸlendi (2 baÅŸarÄ±sÄ±z)...\nâœ… 140 ÅŸehir iÅŸlendi (2 baÅŸarÄ±sÄ±z)...\nâœ… 160 ÅŸehir iÅŸlendi (2 baÅŸarÄ±sÄ±z)...\nâœ… 180 ÅŸehir iÅŸlendi (2 baÅŸarÄ±sÄ±z)...\nâœ… 200 ÅŸehir iÅŸlendi (3 baÅŸarÄ±sÄ±z)...\nâœ… 220 ÅŸehir iÅŸlendi (3 baÅŸarÄ±sÄ±z)...\nâœ… 240 ÅŸehir iÅŸlendi (3 baÅŸarÄ±sÄ±z)...\n\nâœ… 244 ÅŸehir kaydedildi â†’ bronze_weather  (3 ÅŸehir bulunamadÄ±)\n+------------+------------+-------------+------------+\n|city        |country_api |temperature_c|weather_code|\n+------------+------------+-------------+------------+\n|Trujillo    |Peru        |24.5         |3           |\n|Chennai     |India       |24.5         |2           |\n|Medina      |Saudi Arabia|20.7         |0           |\n|Cebu        |Philippines |24.3         |2           |\n|Johannesburg|South Africa|17.4         |1           |\n|Madrid      |Spain       |6.7          |0           |\n|Paris       |France      |10.9         |3           |\n|Subotica    |Serbia      |-0.2         |51          |\n|Vancouver   |Canada      |2.6          |2           |\n|Melbourne   |Australia   |21.1         |2           |\n+------------+------------+-------------+------------+\nonly showing top 10 rows\n\n"]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1bf54ea1-3f48-41e1-9ba9-f4d256ef22dc"},{"cell_type":"markdown","source":["## 2. DÃ¶viz KurlarÄ± (Exchange Rates)"],"metadata":{},"id":"ea03e900-b1a5-4c94-9adf-83b7c543ad91"},{"cell_type":"code","source":["CURRENCY_URL = \"https://open.er-api.com/v6/latest/EUR\"\n","print(\"ğŸ’° Fetching Exchange Rates...\")\n","try:\n","    response = requests.get(CURRENCY_URL, timeout=15)\n","    response.raise_for_status()\n","    data = response.json()\n","\n","    ensure_dir(RAW_EXCHANGE_PATH)\n","    timestamp_str = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    with open(f\"{RAW_EXCHANGE_PATH}/exchange_{timestamp_str}.json\", \"w\") as f:\n","        json.dump(data, f)\n","\n","    rates = data.get(\"rates\", {})\n","    base  = data.get(\"base_code\", \"EUR\")\n","    date_str = data.get(\"time_last_update_utc\")\n","\n","    target_currencies = [\"USD\", \"GBP\", \"JPY\", \"TRY\", \"AED\", \"CNY\"]\n","    records = []\n","    for curr in target_currencies:\n","        if curr in rates:\n","            records.append({\n","                \"base_currency\": base,\n","                \"target_currency\": curr,\n","                \"rate\": float(rates[curr]),\n","                \"timestamp\": date_str,\n","                \"source\": \"exchangerate-api\",\n","                \"ingestion_time\": datetime.datetime.now().isoformat()\n","            })\n","\n","    df_rates = spark.createDataFrame(records)\n","    df_rates_normalized = df_rates \\\n","        .withColumn(\"timestamp\", to_timestamp(col(\"timestamp\"))) \\\n","        .withColumn(\"ingestion_time\", to_timestamp(col(\"ingestion_time\")))\n","\n","    df_rates_normalized.write.format(\"delta\").mode(\"overwrite\") \\\n","        .option(\"overwriteSchema\", \"true\").saveAsTable(EXCHANGE_TABLE)\n","    print(f\"âœ… Exchange Rates Saved â†’ {EXCHANGE_TABLE}\")\n","    df_rates_normalized.show()\n","\n","except Exception as e:\n","    print(f\"âŒ Exchange Rate API Error: {e}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"98d721d9-3f04-46ab-879d-75c970076d05","normalized_state":"finished","queued_time":"2026-02-20T23:37:51.9601468Z","session_start_time":null,"execution_start_time":"2026-02-20T23:39:10.2623527Z","execution_finish_time":"2026-02-20T23:39:20.784922Z","parent_msg_id":"b4876a97-1fca-424b-acc3-800064a977c5"},"text/plain":"StatementMeta(, 98d721d9-3f04-46ab-879d-75c970076d05, 5, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ğŸ’° Fetching Exchange Rates...\nâœ… Exchange Rates Saved â†’ bronze_exchange_rates\n+-------------+--------------------+----------+----------------+---------------+---------+\n|base_currency|      ingestion_time|      rate|          source|target_currency|timestamp|\n+-------------+--------------------+----------+----------------+---------------+---------+\n|          EUR|2026-02-20 23:39:...|  1.177139|exchangerate-api|            USD|     NULL|\n|          EUR|2026-02-20 23:39:...|  0.874196|exchangerate-api|            GBP|     NULL|\n|          EUR|2026-02-20 23:39:...|182.436915|exchangerate-api|            JPY|     NULL|\n|          EUR|2026-02-20 23:39:...|  51.56482|exchangerate-api|            TRY|     NULL|\n|          EUR|2026-02-20 23:39:...|  4.323083|exchangerate-api|            AED|     NULL|\n|          EUR|2026-02-20 23:39:...|  8.135807|exchangerate-api|            CNY|     NULL|\n+-------------+--------------------+----------+----------------+---------------+---------+\n\n"]}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c33bb039-162c-4438-8d0a-f7c2238b80ea"}],"metadata":{"kernelspec":{"display_name":"Synapse PySpark","language":"python","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nbformat":4,"nbformat_minor":4,"nteract":{"version":"nteract-front-end@1.0.0"},"kernel_info":{"name":"synapse_pyspark"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"300fcea7-917c-46f4-b882-033c12af9963"}],"default_lakehouse":"300fcea7-917c-46f4-b882-033c12af9963","default_lakehouse_name":"lh_happybooking","default_lakehouse_workspace_id":"c3fa9526-c341-4b89-a11c-94170caf1f28"}}},"nbformat":4,"nbformat_minor":5}